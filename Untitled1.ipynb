{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Rtk5EUZ37sC5",
        "outputId": "70bc5efd-4707-413e-89e8-5f0434a31d95"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 105)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m105\u001b[0m\n\u001b[0;31m    cv2_imshow(annotated_frame)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "!pip install google-colab-patches\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torch\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, maskrcnn_resnet50_fpn\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "import torchvision.ops as ops\n",
        "import os\n",
        "\n",
        "# Install the required NumPy version\n",
        "try:\n",
        "    import numpy as np\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy<2.0.0\"])\n",
        "    import numpy as np\n",
        "\n",
        "# Download the YOLOv7 repository to a valid location on your Linux machine\n",
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "\n",
        "# Load the YOLOv7-E6E model\n",
        "repo_path = '/content/yolov7' # Update with the correct path to the downloaded repository\n",
        "model_path = '/content/yolov7/yolov7-e6e.pt' # Update with the correct path to the YOLOv7-E6E model file\n",
        "\n",
        "# Verify if the model file exists and handle the case where it's not found\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Error: Model file not found at {model_path}\")\n",
        "    # Handle the error appropriately, e.g., exit the script or download the model\n",
        "    # For this example, we will try to download the model\n",
        "    !wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e.pt -P /content/yolov7/\n",
        "else:\n",
        "    print(\"Model file found. Proceeding...\")\n",
        "\n",
        "yolov7 = torch.hub.load(repo_path, 'custom', model_path, source='local')\n",
        "yolov7.eval()\n",
        "\n",
        "# Load the Faster R-CNN model\n",
        "faster_rcnn = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "faster_rcnn.eval()\n",
        "\n",
        "# Load the Mask R-CNN model\n",
        "mask_rcnn = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "mask_rcnn.eval()\n",
        "\n",
        "# Open the video file\n",
        "video_path = input(\"Enter the path to the video file: \")\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Initialize variables to track the detection results\n",
        "yolov7_detections = []\n",
        "faster_rcnn_detections = []\n",
        "mask_rcnn_detections = []\n",
        "\n",
        "# Initialize flags to track the presence of drones and birds\n",
        "drone_detected = False\n",
        "bird_detected = False\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to a PIL image\n",
        "    img = Image.fromarray(frame)\n",
        "\n",
        "    # Make predictions using YOLOv7-E6E\n",
        "    yolov7_results = yolov7(img) # Now yolov7 is defined and this line should execute without error\n",
        "    yolov7_detections = yolov7_results.pandas().xyxy[0].to_numpy()\n",
        "\n",
        "\n",
        "    yolov7_detections = yolov7_results.pandas().xyxy[0].to_numpy()\n",
        "\n",
        "    normalized_frame = torch.tensor(np.transpose(frame, (2, 0, 1)) / 255.0, dtype=torch.float32)\n",
        "    faster_rcnn_results = faster_rcnn([normalized_frame])\n",
        "    faster_rcnn_detections = faster_rcnn_results[0]['boxes'].detach().numpy()\n",
        "\n",
        "    # Make predictions using Mask R-CNN\n",
        "    # Normalize the frame to be between 0 and 1 and convert it to float32\n",
        "    mask_rcnn_results = mask_rcnn([normalized_frame])\n",
        "    mask_rcnn_detections = mask_rcnn_results[0]['boxes'].detach().numpy()\n",
        "\n",
        "\n",
        "    # Check if a drone or bird is detected\n",
        "    for box in yolov7_detections:\n",
        "        if box[5] == 0:  # Drone class\n",
        "            drone_detected = True\n",
        "        elif box[5] == 16:  # Bird class\n",
        "            bird_detected = True\n",
        "\n",
        "    # Display the frame with bounding boxes\n",
        "    annotated_frame = frame.copy()\n",
        "    for box in yolov7_detections:\n",
        "        x1, y1, x2, y2 = [int(v) for v in box[:4]]\n",
        "        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    for box in faster_rcnn_detections:\n",
        "        x1, y1, x2, y2 = [int(v) for v in box]\n",
        "        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "    for box in mask_rcnn_detections:\n",
        "        x1, y1, x2, y2 = [int(v) for v in box]\n",
        "        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "   cv2_imshow(annotated_frame)\n",
        "    # Check if the user wants to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close the window\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Print the detection results\n",
        "if drone_detected:\n",
        "    print(\"Drone detected in the video.\")\n",
        "else:\n",
        "    print(\"No drone detected in the video.\")\n",
        "\n",
        "if bird_detected:\n",
        "    print(\"Bird detected in the video.\")\n",
        "else:\n",
        "    print(\"No bird detected in the video.\")\n"
      ]
    }
  ]
}